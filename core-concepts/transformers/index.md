# Transformer

Transformer 是机器学习 Pipeline 执行的基本单元。一个 Transformer 以一帧 Data Frame 作为输入，执行某些转换操作，输出包含一个或者多个新字段的数据到原来的 Data Frame 中。虽然要做的事情很简单，但它是 Spark、Scikit-Learn、MLeap 和 TensorFlow 执行引擎的核心部分。

Transformer 被用于许多用途，但在机器学习中，最常见的用途是：

1. 特征提取
2. 模型评分

## 特征提取

特征提取用于从一个输入数据数据集中提取一个或者多个特征，延生成一个新的特征。在我们 Data Frame 的例子中，特征来源自输入 Data Frame，并被写入到输出 Data Frame 中。

一些特征提取的例子：

1. 字符串索引（标签编码） - 将一个字符串转换为整型值。
2. 将整型值转换为 0 / 1 的二值向量。
3. 特征选择 - 分析哪一个特征能够更有效地训练出一个用于预测的机器学习算法（比如 CHI2）。
4. 数学运算 - 基础的数学函数，比如将两个特征的值相互相除，或者求一个特征值的 log 值。

有太多的特征提取操作可以去列举，你可以参见[支持的特征 Transformer](support.html#features) 章节来获得完整的支持列表。

## 回归

回归（Regression）用于预测一个连续值，比如一辆车或者一套房子的价格。在大多数情况下回归模型会操作一个被称为 “特征向量” 的浮点数值向量，这个特征向量包含了所有需要被用于预测的信息。以预测房价为例，特征向量会包含编码过的房子所在地区信息、面积信息、房间数量信息、房龄信息，等等。

参见[支持的回归模型](support.html#regression)页面获得完整列表。

## 分类

分类（Classification）用于预测离散值。比如预测是否应该给用户贷款，或者预测一个 .wav 文件内包含了什么类型的声音，又或者是图片中是否有一个人类。

[支持的分类模型](support.html#classification).

## 聚类

聚类（Clustering）用于给相似的数据打上标签（也就是做分类或者聚合）。类似于分类，得到的结果是一个集合里面的离散值，但与分类不同的是，聚类模型属于非监督模型，他的训练数据并没有已经贴好标签。聚类对于特征功能、异常检测等领域非常有用。

[支持的聚类模型](support.html#clustering).

## 其他类型的 Transformer

Transformer 无所不能！以上仅仅只是一些典型的例子，你也可以构建 Transformer 来调整图片尺寸、重采样声音数据，从不同的数据源获取得到数据，无所拘束地去做任何你想做的事情。